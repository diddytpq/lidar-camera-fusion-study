{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "46cd75ab",
   "metadata": {},
   "outputs": [],
   "source": [
    "import argparse\n",
    "import cv2\n",
    "import numpy as np\n",
    "import os\n",
    "import pdb\n",
    "\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "from model.anchors import Anchors, anchor_target, anchors2bboxes\n",
    "from ops import Voxelization, nms_cuda\n",
    "from utils import limit_period\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "9159529e",
   "metadata": {},
   "outputs": [],
   "source": [
    "def point_range_filter(pts, point_range=[0, -39.68, -3, 69.12, 39.68, 1]):\n",
    "    '''\n",
    "    data_dict: dict(pts, gt_bboxes_3d, gt_labels, gt_names, difficulty)\n",
    "    point_range: [x1, y1, z1, x2, y2, z2]\n",
    "    논문에 표기된 대로 car, pedstrian cyclist를 검출하는 포인터 범위\n",
    "    '''\n",
    "    flag_x_low = pts[:, 0] > point_range[0] # 0\n",
    "    flag_y_low = pts[:, 1] > point_range[1] # -39.68\n",
    "    flag_z_low = pts[:, 2] > point_range[2] # -3\n",
    "    flag_x_high = pts[:, 0] < point_range[3] # 69.12\n",
    "    flag_y_high = pts[:, 1] < point_range[4] # 39.68\n",
    "    flag_z_high = pts[:, 2] < point_range[5] # 1\n",
    "    keep_mask = flag_x_low & flag_y_low & flag_z_low & flag_x_high & flag_y_high & flag_z_high\n",
    "    pts = pts[keep_mask]\n",
    "    return pts "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "5556873d",
   "metadata": {},
   "outputs": [],
   "source": [
    "pc_file_list = sorted(os.listdir(\"dataset/testing/velodyne/\"))\n",
    "\n",
    "input_pc_path = \"dataset/testing/velodyne/\" + pc_file_list[3]\n",
    "\n",
    "suffix = os.path.splitext(input_pc_path)[1]\n",
    "\n",
    "input_pc = np.fromfile(input_pc_path, dtype=np.float32).reshape(-1, 4)\n",
    "\n",
    "input_pc_fillered = point_range_filter(input_pc)\n",
    "\n",
    "pc_torch = torch.from_numpy(input_pc_fillered)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "06cb63eb",
   "metadata": {},
   "outputs": [
    {
     "ename": "TypeError",
     "evalue": "'int' object is not subscriptable",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32m/home/drcl/workspace/lidar-camera-fusion-study/lidar_based/PointPillars/Untitled.ipynb Cell 7\u001b[0m in \u001b[0;36m<cell line: 1>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      <a href='vscode-notebook-cell:/home/drcl/workspace/lidar-camera-fusion-study/lidar_based/PointPillars/Untitled.ipynb#W6sZmlsZQ%3D%3D?line=0'>1</a>\u001b[0m \u001b[39mfor\u001b[39;00m i, pts \u001b[39min\u001b[39;00m \u001b[39menumerate\u001b[39m([pc_torch]):\n\u001b[1;32m      <a href='vscode-notebook-cell:/home/drcl/workspace/lidar-camera-fusion-study/lidar_based/PointPillars/Untitled.ipynb#W6sZmlsZQ%3D%3D?line=1'>2</a>\u001b[0m     \u001b[39m# print(pts.new_zeros())\u001b[39;00m\n\u001b[0;32m----> <a href='vscode-notebook-cell:/home/drcl/workspace/lidar-camera-fusion-study/lidar_based/PointPillars/Untitled.ipynb#W6sZmlsZQ%3D%3D?line=2'>3</a>\u001b[0m     voxel_layer(pts)\n",
      "File \u001b[0;32m~/anaconda3/envs/pillars/lib/python3.8/site-packages/torch/nn/modules/module.py:1102\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[0;34m(self, *input, **kwargs)\u001b[0m\n\u001b[1;32m   1098\u001b[0m \u001b[39m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[1;32m   1099\u001b[0m \u001b[39m# this function, and just call forward.\u001b[39;00m\n\u001b[1;32m   1100\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mnot\u001b[39;00m (\u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_backward_hooks \u001b[39mor\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_forward_hooks \u001b[39mor\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_forward_pre_hooks \u001b[39mor\u001b[39;00m _global_backward_hooks\n\u001b[1;32m   1101\u001b[0m         \u001b[39mor\u001b[39;00m _global_forward_hooks \u001b[39mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[0;32m-> 1102\u001b[0m     \u001b[39mreturn\u001b[39;00m forward_call(\u001b[39m*\u001b[39;49m\u001b[39minput\u001b[39;49m, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwargs)\n\u001b[1;32m   1103\u001b[0m \u001b[39m# Do not call functions when jit is used\u001b[39;00m\n\u001b[1;32m   1104\u001b[0m full_backward_hooks, non_full_backward_hooks \u001b[39m=\u001b[39m [], []\n",
      "File \u001b[0;32m~/workspace/lidar-camera-fusion-study/lidar_based/PointPillars/ops/voxel_module.py:119\u001b[0m, in \u001b[0;36mVoxelization.forward\u001b[0;34m(self, input)\u001b[0m\n\u001b[1;32m    117\u001b[0m     max_voxels \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mmax_voxels[\u001b[39m0\u001b[39m]\n\u001b[1;32m    118\u001b[0m \u001b[39melse\u001b[39;00m:\n\u001b[0;32m--> 119\u001b[0m     max_voxels \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mmax_voxels[\u001b[39m1\u001b[39;49m]\n\u001b[1;32m    121\u001b[0m \u001b[39mreturn\u001b[39;00m _Voxelization\u001b[39m.\u001b[39mapply(\u001b[39minput\u001b[39m, \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mvoxel_size, \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mpoint_cloud_range,\n\u001b[1;32m    122\u001b[0m                            \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mmax_num_points, max_voxels,\n\u001b[1;32m    123\u001b[0m                            \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mdeterministic)\n",
      "\u001b[0;31mTypeError\u001b[0m: 'int' object is not subscriptable"
     ]
    }
   ],
   "source": [
    "for i, pts in enumerate([pc_torch]):\n",
    "    # print(pts.new_zeros())\n",
    "    voxel_layer(pts)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "a9955f8d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[22.3920,  4.3760,  0.9810,  0.3800],\n",
       "        [22.4780,  4.4660,  0.9840,  0.2700],\n",
       "        [21.9480,  4.4320,  0.9660,  0.2100],\n",
       "        ...,\n",
       "        [ 3.7410, -1.4020, -1.7470,  0.4700],\n",
       "        [ 3.7400, -1.3880, -1.7440,  0.0000],\n",
       "        [ 5.5840, -1.8490, -2.6270,  0.0000]])"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "a"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "aace5075",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0\n",
      "tensor([[22.3920,  4.3760,  0.9810,  0.3800],\n",
      "        [22.4780,  4.4660,  0.9840,  0.2700],\n",
      "        [21.9480,  4.4320,  0.9660,  0.2100],\n",
      "        ...,\n",
      "        [ 3.7410, -1.4020, -1.7470,  0.4700],\n",
      "        [ 3.7400, -1.3880, -1.7440,  0.0000],\n",
      "        [ 5.5840, -1.8490, -2.6270,  0.0000]])\n"
     ]
    }
   ],
   "source": [
    "for i, pts in enumerate([a]):\n",
    "    print(i)\n",
    "    print(pts)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "eab2cde6",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.8.13 ('pillars')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.13"
  },
  "vscode": {
   "interpreter": {
    "hash": "9a272d058f02466131663a98fde0a5fb028fb2427dbe553090c2dd1c9aa10e44"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
